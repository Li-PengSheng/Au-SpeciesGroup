"0","# More that 100 occurance we consider them as a outliers, drop the rows"
"0","  #data_2022 |> dplyr::summarise(n_over_100 = sum(occurrence_count > 100, na.rm = TRUE), prop_over_100 =            mean(occurrence_count > 100, na.rm = TRUE))"
"0",""
"0","      #Output"
"0","      #n_over_100 prop_over_100"
"0","      #684        0.00229916    "
"0",""
"0","data_2022 <- data_2022 |> dplyr::filter(occurrence_count <= 100)  "
"0","  #nrow(data_2022)"
"0",""
"0","    #Output"
"0","    #296816"
"0",""
"0","# Drop the duplicate rows"
"0","data_2022 <- data_2022 |> distinct()"
"0","  #nrow(data_2022)"
"0",""
"0","    #Output"
"0","    #293063"
"0",""
"0","# Species names with >1 distinct species_id"
"0","names_many_ids <- data_2022 |>"
"0","  group_by(species_name) |>"
"0","  summarise(n_distinct_ids = n_distinct(species_id, na.rm = TRUE), .groups = ""drop"") |>"
"0","  filter(!is.na(species_name), n_distinct_ids > 1)"
"0",""
"0","# Drop those rows from data2"
"0","data_2022 <- data_2022 |>"
"0","  anti_join(names_many_ids |> select(species_name), by = ""species_name"")"
"0",""
"0","summary_after <- tibble("
"0","  rows_after      = nrow(data_2022),"
"0","  names_dropped_n = nrow(names_many_ids)"
"0",")"
"0","  #summary_after"
"0",""
"0","    #Output"
"0","    #rows_after names_dropped_n"
"0","    #292865    8    "
"0",""
"0","write.csv(data_2022, ""cleaned.csv"", row.names = FALSE)"
