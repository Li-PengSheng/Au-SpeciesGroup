"0","# 1. Extract cross-validation results"
"0","dt_cv_results <- dt_model$results %>%"
"0","  filter(cp == dt_model$bestTune$cp) %>%"
"0","  select(Kappa, Accuracy, Mean_F1, Mean_Sensitivity, Mean_Specificity)"
"0",""
"0","svm_cv_results <- svm_model$results %>%"
"0","  filter(cost == svm_model$bestTune$cost) %>%"
"0","  select(Kappa, Accuracy, Mean_F1, Mean_Sensitivity, Mean_Specificity)"
"0",""
"0","# 2. Test set predictions"
"0","dt_pred <- predict(dt_model, newdata = test_data)"
"0","svm_pred <- predict(svm_model, newdata = test_data)"
"0",""
"0","# 3. Test set performance"
"0","dt_test_perf <- confusionMatrix(dt_pred, test_data$Type)"
"0","svm_test_perf <- confusionMatrix(svm_pred, test_data$Type)"
"0",""
"0","# 4. Compile comparison table"
"0","model_comparison <- data.frame("
"0","  Model = c(""Decision Tree"", ""SVM (Linear)""),"
"0",""
"0","  # Cross-validation metrics"
"0","  CV_Kappa = c(dt_cv_results$Kappa, svm_cv_results$Kappa),"
"0","  CV_Accuracy = c(dt_cv_results$Accuracy, svm_cv_results$Accuracy),"
"0","  CV_F1 = c(dt_cv_results$Mean_F1, svm_cv_results$Mean_F1),"
"0",""
"0","  # Test set metrics"
"0","  Test_Kappa = c("
"0","    dt_test_perf$overall[""Kappa""],"
"0","    svm_test_perf$overall[""Kappa""]"
"0","  ),"
"0","  Test_Accuracy = c("
"0","    dt_test_perf$overall[""Accuracy""],"
"0","    svm_test_perf$overall[""Accuracy""]"
"0","  ),"
"0",""
"0","  # Best hyperparameters"
"0","  Best_Param = c("
"0","    paste0(""cp = "", round(dt_model$bestTune$cp, 4)),"
"0","    paste0(""cost = "", svm_model$bestTune$cost)"
"0","  ),"
"0",""
"0","  # Training time"
"0","  Time_mins = c(as.numeric(total_time_dt), as.numeric(total_time_svm))"
"0",")"
"0",""
"0","# Round numeric columns"
"0","model_comparison[, 2:6] <- round(model_comparison[, 2:6], 4)"
"0","model_comparison$Time_mins <- round(model_comparison$Time_mins, 2)"
"0",""
"0","print(model_comparison)"
